{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: 06/19/2019\n",
    "\n",
    "## Brief: What was done previously\n",
    "Previous work discovered a new architecture that approximated a PDE\n",
    "\n",
    "## Hypothesis\n",
    "1. Including local values in feature embedding improves prediction\n",
    "1. Adding valid bit-mask to kernels reduces edge effects\n",
    "1. Using richer feature space reduces edge effects\n",
    "1. Typical PDE formulation is sensitive to noise peturbations\n",
    "1. LSTM based end-to-end model is less sensitive but much larger\n",
    "1. Using a deeper embetting network imporves resistance to noise\n",
    "1. Using RK4 approximation improves prediction perfomance\n",
    "\n",
    "\n",
    "## Summary of Main Results and Discussions\n",
    "Modeled new architecture that uses skip layers to approximate PDE\n",
    "\n",
    "New architecture achieves better performance fig ? with fewer model parameters. Additionally, this formulation is \n",
    "more natural for learned functions allowing approximation by traditional PDE equations after learning a deep model.\n",
    "\n",
    "\n",
    "### Hypothesis 1 results and discussion\n",
    "New PDE net architecture learns embedding well using only per-point history.\n",
    "\n",
    "### Experiment 2: results and discussion\n",
    "Put main result and conclusions here. Discuss importance/impact in terms of the project goals.\n",
    "\n",
    "\n",
    "## Plan for next effort\n",
    "Test architectures that remove the edge effect / dont penalize edge effects for patches\n",
    "Perform hyper parameter optimization\n",
    "Test training at multiple scales (LM-architecture)\n",
    "Test the temporal consistency of networks\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hypothesis 1\n",
    "### Including local values in feature encoding improves prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the effect of using 1x1, 3x3, and 5x5 kernels for feature encoding\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import src.predict_pde_recurrent\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "completed = [] #itertools.product([5, 3, 1], [20, 10, 5])\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "for encoding_kernel_size, pred_len in itertools.product([5, 3, 1], [20, 10, 5]):\n",
    "    if (encoding_kernel_size, pred_len) not in completed:\n",
    "        name = 'enc_kernel_{}_test-conv_3-skip_1-cell'.format(encoding_kernel_size)\n",
    "        num_batches = 15000 + pred_len * 1000        \n",
    "        model = src.predict_pde_recurrent.train(net_name=name, \n",
    "                                                encoder_kernel_size=encoding_kernel_size,\n",
    "                                                pred_length=pred_len, \n",
    "                                                history_length=5,\n",
    "                                                num_batches=num_batches)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accruacy of different runs\n",
    "import os\n",
    "import glob\n",
    "# import itertools\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "completed = list(itertools.product([5, 3, 1], [20, 10, 5]))\n",
    "\n",
    "\n",
    "# exp_root = 'F:\\\\'\n",
    "exp_root = 'C:\\\\Users\\\\brandon\\\\source\\\\orbitalMechanics\\\\experiments\\\\turbulence\\\\pde\\\\'\n",
    "exp_folders = [exp_root + 'enc_kernel_{}_test-conv_3-skip_1-cell_0.0005-lr_5-hist_{}-pred'.format(k, l) for (k,l) in completed]\n",
    "# exp_folders = glob.glob(exp_root + '/enc_kernel_[0-9]*_test-conv_3-skip_1-cell*30-pred')\n",
    "npys = ['train_accuracy_by_time.npz', 'validation_accuracy_by_time.npz']\n",
    "\n",
    "train_data = []\n",
    "validation_data = []\n",
    "diff = []\n",
    "print(len(exp_folders),len(completed))\n",
    "\n",
    "for i, (directory, (k,l)) in enumerate(zip(exp_folders, completed)):\n",
    "    # Load input, prediction and label\n",
    "    try:\n",
    "        if all([os.path.exists(os.path.join(exp_root, directory, f)) for f in npys]):\n",
    "            ts = '10000'\n",
    "            for key in set(train_acc.keys()).intersection(valid_acc.keys()):\n",
    "                if int(key) > int(ts) or ts is None:\n",
    "                    ts = key\n",
    "            print(ts)\n",
    "            train_acc_dir, valid_acc_dir = [os.path.join(exp_root, directory, f) for f in npys]\n",
    "\n",
    "            with np.load(train_acc_dir) as train_acc, np.load(valid_acc_dir) as valid_acc:\n",
    "                train_data.append(\n",
    "                    go.Scatter(\n",
    "                        x = list(range(train_acc[ts].shape[0])),\n",
    "                        y = train_acc[ts], \n",
    "                        name = 'kernel_size={} len={}'.format(k, l)))\n",
    "                validation_data.append(\n",
    "                    go.Scatter(\n",
    "                        x = list(range(valid_acc[ts].shape[0])),\n",
    "                        y = valid_acc[ts], \n",
    "                        name = 'kernel_size={} len={}'.format(k, l)))\n",
    "                diff.append(\n",
    "                    go.Scatter(\n",
    "                        x = list(range(valid_acc[ts].shape[0])),\n",
    "                        y = valid_acc[ts] - train_acc[ts], \n",
    "                        name = 'kernel_size={} len={}'.format(k, l)))\n",
    "        else:\n",
    "            print('skipped', directory)\n",
    "    except KeyError:\n",
    "        continue\n",
    "            \n",
    "layout = go.Layout(\n",
    "    title=\"Prediction Accuracy by Time Horizon - Train\",\n",
    "    xaxis=dict(\n",
    "        type='linear',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Predicted time step, t',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean squared validation error n = 20',\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig = go.Figure(data=train_data, layout=layout)\n",
    "py.iplot(fig, filename='acc_over_time_noise_study_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2\n",
    "### Reduce scope of local values for pde estimation (lower cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the effect of using 1x1, 3x3, and 5x5 kernels for pde layer encoding\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import src.predict_pde_recurrent\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "completed = [] #itertools.product([5, 3, 1], [20, 10, 5])\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "for kernel_size, pred_len in itertools.product([5, 3, 1], [20, 10, 5]):\n",
    "    if (kernel_size, pred_len) not in completed:\n",
    "        name = 'kernel_size_{}-conv_3-skip_1-cell'.format(kernel_size)\n",
    "        num_batches = 15000 + pred_len * 1000        \n",
    "        model = src.predict_pde_recurrent.train(net_name=name, \n",
    "                                                conv_width=kernel_size,\n",
    "                                                pred_length=pred_len, \n",
    "                                                history_length=5,\n",
    "                                                num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Problem formulation\n",
    "Let $x$ represent h patches of history $x = [x_{t-h}, ..., x_{t-1}]$ and y represent the target sequence $y = \n",
    "[x_{t}, x_{t+1},...,x_{t+l-1}]$.  We learn an encoder, $\\phi(x) = u_0$, a decoder $\\theta(u_n) = \\hat{y}_n$ and a \n",
    "dynamics model $f(u_n)$ from equation \\ref{eqn:ode}    \n",
    "Rather \n",
    "than \n",
    "explicitly parameterizing the ODE on derivatives of $x$, we instead consider a system of ordinary differential\n",
    " equations of dimension m = 16. We then learn the encoding from 5 frames of history \n",
    " encoding local features via\n",
    " \n",
    " Thus we learn a series of features $w_{enc}$ such that $u_0 = relu(x * w_{enc})$.\n",
    " We approximate the dynamics $f(u)$ by    $f(u_n)$ by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "completed = [(5,5), (5,20), (5,40), (5,60)]\n",
    "\n",
    "for (history, pred_len) in itertools.product([5, 20], [5, 20, 40, 60]):\n",
    "    if (history, pred_len) not in completed:\n",
    "        name = 'conv_3-skip_1-cell'\n",
    "        num_batches = 15000 + pred_len * 1000\n",
    "        model = src.predict_pde_recurrent.train(net_name=name, pred_length=pred_len, history_length=history, \n",
    "                                                num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import importlib\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "Deep recurrent networks are tolerant to sensor noise below a certain magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure accuracy over increasing fixed gaussian sensor noise\n",
    "We add increasing magnitudes of gaussian noise to the input and predict the clean original signal. We expect, for\n",
    "high levels of noise, the model to over-fit to the noise. However, after some threshold we expect the model to learn to recover from small perturbations by learning the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian noise study (fixed input noise)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.predict_pde_recurrent import train\n",
    "from src.dataLoader.turbulence import Turbulence, RANDOM_SEED, LARGE_DATASET\n",
    "\n",
    "# Use a fixed seed for noise    \n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for scale in [0, 0.01, 0.05, 0.1, 0.25]:\n",
    "    noise_data = np.random.normal(size=(360, 279, 1000), scale=scale)\n",
    "    \n",
    "    loader = Turbulence(pred_length=40, dataset_idx=LARGE_DATASET, input_noise=noise_data, debug=False)\n",
    "    \n",
    "    train(loader=loader, dataset_idx=LARGE_DATASET, num_batches=50000, net_name='PDE_3-skip_1-cell_resnet_static_noise_{}'.format(scale))\n",
    "    \n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results - Hypothesis 1\n",
    "\n",
    "In this test given a 3 layer encoder/decoder model with 250 units per layer, we see that the performance of the model is \n",
    "resistant to up to 5% noise without any degradation. Further noise causes significant increases in L2 loss porportinal to the magnitude of of noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/50.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare accuracy of model with increasing fixed noise\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import plotly\n",
    "\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "plt.rc('text', usetex=True)\n",
    "    \n",
    "# Compare MSE vs magnitude of noise\n",
    "noise = [2, 1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.0001, 0]\n",
    "noise.reverse()\n",
    "train_accuracy = [1.836e-5, 1.8441e-5, 2.0871e-5, 2.0525e-5, 2.0918e-5, 2.2431e-5, 2.2850e-5, 3.6688e-5, 6.5500e-5, 7.1376e-5, 7.3004e-5, 7.1560e-5, 1.1372e-4]\n",
    "validation_accuracy = [1.932e-5, 1.9536e-5, 2.1711e-5, 2.1794e-5, 2.1213e-5, 2.3923e-5, 2.4532e-5, 4.2984e-5, 1.0194e-4, 2.9481e-4, 5.4323e-4, 7.5883e-4, 2.0583e-3]\n",
    "\n",
    "# Create a trace\n",
    "trace1 = go.Scatter(\n",
    "    x = noise,\n",
    "    y = validation_accuracy,\n",
    "    name=\"validation\"\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = noise,\n",
    "    y = train_accuracy,\n",
    "    name=\"train\"\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    title=\"Magnitude of Sensor Noise vs L2 Loss\",\n",
    "    xaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Standard Deviation of Added Gaussian Noise',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean Squared Validation Error n=20',\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='static_noise_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/54.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title=\"Magnitude of Sensor Noise vs L2 Loss\",\n",
    "    xaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Standard Deviation of Added Gaussian Noise',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean Squared Error n = 20',\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='static_noise_model_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped runge_kutta_growing_pred_len_sigmoid_6k_per_step_batch_norm_8_features_5_layers_0.001-lr_5-hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/60.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy over time\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# exp_root = 'F:\\\\'\n",
    "exp_root = 'C:\\\\Users\\\\brandon\\\\source\\\\orbitalMechanics\\\\experiments\\\\turbulence\\\\pde'\n",
    "exp_folders = ['rk4_3_enc_2_dec_8_feat_3_skip_0.001-lr_5-hist',\n",
    "                'runge_kutta_growing_pred_len_sigmoid_6k_per_step_batch_norm_8_features_5_layers_0.001-lr_5-hist',\n",
    "               'lstm_3_cells_p20_static_noise_0_velocity_and_vorticity_field_1200s.mat_lr0.0005', \n",
    "               'linear_predictor_0.001-lr_1-hist'\n",
    "              ]\n",
    "npys = ['train_accuracy_by_time_113999.npz', 'validation_accuracy_by_time_113999.npz']\n",
    "nnpys = ['train_accuracy_by_time.npz', 'validation_accuracy_by_time.npz']\n",
    "nnnpys = ['train_accuracy_by_time_15534.npz', 'validation_accuracy_by_time_15534.npz']\n",
    "# npys = ['train_accuracy_by_time_341999.npz', 'validation_accuracy_by_time_341999.npz']\n",
    "\n",
    "\n",
    "\n",
    "names= ['RK4 Approx.', 'Previous Result', 'Forward Euler Approx.', 'Linear Model']\n",
    "train_data = []\n",
    "validation_data = []\n",
    "diff = []\n",
    "\n",
    "for i, directory in enumerate(exp_folders):\n",
    "    # Load input, prediction and label\n",
    "    try:\n",
    "        if all([os.path.exists(os.path.join(exp_root, directory, f)) for f in npys]):\n",
    "            train_acc_dir, valid_acc_dir = [os.path.join(exp_root, directory, f) for f in npys]\n",
    "        elif all([os.path.exists(os.path.join(exp_root, directory, f)) for f in nnpys]):\n",
    "            train_acc_dir, valid_acc_dir = [os.path.join(exp_root, directory, f) for f in nnpys]\n",
    "        elif all([os.path.exists(os.path.join(exp_root, directory, f)) for f in nnnpys]):\n",
    "            train_acc_dir, valid_acc_dir = [os.path.join(exp_root, directory, f) for f in nnnpys]\n",
    "        else:\n",
    "            print('skipped', directory)\n",
    "            continue\n",
    "            \n",
    "        with np.load(train_acc_dir) as train_acc, np.load(valid_acc_dir) as valid_acc:\n",
    "            ts = max(train_acc.keys())\n",
    "            train_data.append(\n",
    "                go.Scatter(\n",
    "                    x = list(range(train_acc[ts].shape[0])),\n",
    "                    y = train_acc[ts], \n",
    "                    name = names[i]))\n",
    "            vs = max(valid_acc.keys())\n",
    "            validation_data.append(\n",
    "                go.Scatter(\n",
    "                    x = list(range(valid_acc[vs].shape[0])),\n",
    "                    y = valid_acc[vs] * (10 if i == 2 else 1), \n",
    "                    name = names[i]))\n",
    "            diff.append(\n",
    "                go.Scatter(\n",
    "                    x = list(range(valid_acc[vs].shape[0])),\n",
    "                    y = valid_acc[vs] - train_acc[ts], \n",
    "                    name = names[i]))\n",
    "    except KeyError:\n",
    "        continue\n",
    "            \n",
    "layout = go.Layout(\n",
    "    title=\"Prediction Accuracy by Time Horizon - Train\",\n",
    "    xaxis=dict(\n",
    "        type='linear',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Predicted time step, t',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean squared validation error n = 20',\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig = go.Figure(data=train_data, layout=layout)\n",
    "py.iplot(fig, filename='acc_over_time_noise_study_train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/62.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Prediction Accuracy by Time Horizon\",\n",
    "    xaxis=dict(\n",
    "        type='linear',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Predicted time step, t',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean squared validation error n = 20',\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig = go.Figure(data=validation_data, layout=layout)\n",
    "py.iplot(fig, filename='acc_over_time_noise_study_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/64.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Prediction Accuracy by Time Horizon - Difference\",\n",
    "    xaxis=dict(\n",
    "        type='linear',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Predicted time step, t',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Diffrence in MSE between train and validation; n = 20',\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig = go.Figure(data=diff, layout=layout)\n",
    "py.iplot(fig, filename='acc_over_time_noise_study_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small magnitude of fixed noise increases generalization to new samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "exp_root = 'F:\\\\'\n",
    "exp_folders = ['lstm_5_cells_dropout_60_static_noise_{}_velocity_and_vorticity_field_1200s.mat_lr0.0001'.format(n) for n in noise]\n",
    "npys = ['train_accuracy_by_time.npz', 'validation_accuracy_by_time.npz']\n",
    "\n",
    "train = []\n",
    "validation = []\n",
    "x = []\n",
    "\n",
    "\n",
    "for i, directory in enumerate(exp_folders):\n",
    "    # Load input, prediction and label\n",
    "    if all([os.path.exists(os.path.join(exp_root, directory, f)) for f in npys]):\n",
    "        ts = '50000'\n",
    "        train_acc_dir, valid_acc_dir = [os.path.join(exp_root, directory, f) for f in npys]\n",
    "\n",
    "        with np.load(train_acc_dir) as train_acc, np.load(valid_acc_dir) as valid_acc:\n",
    "            try:\n",
    "                train.append(train_acc[ts][19]) \n",
    "                validation.append(valid_acc[ts][19])\n",
    "                x.append(noise[i] + 0.0001)\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "train_data = go.Scatter(\n",
    "        x = x,\n",
    "        y = train, \n",
    "        name = 'train',\n",
    "        text=[str(p - 0.0001) for p in x])\n",
    "validation_data = go.Scatter(\n",
    "        x = x,\n",
    "        y = validation, \n",
    "        name = 'validation',\n",
    "        text=[str(p - 0.0001) for p in x])\n",
    "            \n",
    "layout = go.Layout(\n",
    "    title=\"Sensor noise vs prediction error at step t+20\",\n",
    "    xaxis=dict(\n",
    "        type='linear',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Standard deviation of added fixed gaussian noise',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        tickmode = 'array',\n",
    "        autorange=True,\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e',\n",
    "        title='Mean squared validation error at step t+20',\n",
    "    )\n",
    ")\n",
    "data=[validation_data]\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='acc_over_time_noise_study_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize noise data\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Make sub-plots for input sequence\n",
    "plt.rc('text', usetex=True)\n",
    "fig, plots = plt.subplots(5, 8, figsize=(24, 17))\n",
    "\n",
    "exp_root = 'F:\\\\'\n",
    "exp_folders = ['lstm_5_cells_dropout_60_static_noise_{}_velocity_and_vorticity_field_1200s.mat_lr0.0001'.format(n) for n in noise]\n",
    "titles = ['Sequence + N $\\sig = {} \\mu = 0$'.format(n) for n in noise if n != 0.0001]\n",
    "titles = [r\"$X + \\mathcal{N}(\\mu,\\,\\sigma^{2}=\" + str(n) + \") $\" for n in noise if n != 0.0001]\n",
    "\n",
    "for j in range(5):\n",
    "    for i, directory in enumerate(exp_folders[:8]):\n",
    "        for file in os.listdir(os.path.join(exp_root, directory)):\n",
    "            if file.endswith('.npz') and file.startswith('inputs'):\n",
    "                file_path = os.path.join(exp_root, directory, file)\n",
    "                with np.load(file_path) as foo:\n",
    "                    try:\n",
    "                        plots[j, i].imshow(np.reshape(foo['100000'][j*4, 0,:], (50,50)))\n",
    "                        plots[j, i].set_title(titles[i], fontsize=16, color='gray')\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "    \n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make videos of label, prediction, and difference\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Video parameters\n",
    "fps = 10\n",
    "height, width = 50, 50\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "\n",
    "# Convert [0, 1] np.float32 to [0, 255] RGB cv2.uint8\n",
    "cmap = plt.get_cmap('jet')\n",
    "def convert_img(img):\n",
    "    mapped = cmap(img)\n",
    "    return cv2.normalize(mapped[:,:,:3], None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "def add_lables(img):\n",
    "    font = cv2.FONT_HERSHEY_TRIPLEX \n",
    "    cv2.putText(img,'X',(10,40), font, 0.4,(0,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,'f(X)',(10,90), font, 0.4,(0,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,'Y',(10,140), font, 0.4,(0,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,'|f(x) - y|^2', (10,190), font, 0.4,(0,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,'X',(10,40), font, 0.4,(255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(img,'f(X)',(10,90), font, 0.4,(255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(img,'Y',(10,140), font, 0.4,(255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(img,'|f(x) - y|^2', (10,190), font, 0.4,(255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "# initialize video writer\n",
    "video_filename = 'output.avi'\n",
    "\n",
    "# noise = [2, 1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.0001, 0]\n",
    "\n",
    "\n",
    "exp_root = 'C:\\\\Users\\\\brandon\\\\source\\\\orbitalMechanics\\\\experiments\\\\turbulence\\\\pde'\n",
    "exp_folders = ['kernel_size_{}-conv_3-skip_1-cell_0.0005-lr_5-hist_{}-pred'.format(h,l) \n",
    "                for h,l in itertools.product([5, 3, 1], [20, 10, 5])]\n",
    "titles = ['kernel_size_{}, len={}'.format(h,l) for h,l in itertools.product([5, 3, 1], [20, 10, 5])]\n",
    "npys = ['inputs.npz', 'predictions.npz', 'labels.npz']\n",
    "\n",
    "for i, directory in enumerate(exp_folders):\n",
    "    # Load input, prediction and label\n",
    "    if all([os.path.exists(os.path.join(exp_root, directory, f)) for f in npys]):\n",
    "        print('rendering video for', directory)\n",
    "        input_dir, pred_dir, label_dir = [os.path.join(exp_root, directory, f) for f in npys]\n",
    "\n",
    "        with np.load(input_dir) as inputs, np.load(pred_dir) as predictions, np.load(label_dir) as labels:\n",
    "            ts = '10000'\n",
    "            for key in set(inputs.keys()).intersection(predictions.keys()):\n",
    "                if int(key) > int(ts) or ts is None:\n",
    "                    ts = key\n",
    "            print(ts)\n",
    "            out = cv2.VideoWriter(directory + '.avi', fourcc, fps, (width*16, height*4))\n",
    "\n",
    "            # First show input sequence\n",
    "            for i in range(inputs[ts].shape[0]):\n",
    "                top = np.concatenate(\n",
    "                        [np.reshape(inputs[ts][i, j,:], (50,50)) for j in range(16)], axis=1)\n",
    "                mid = np.concatenate(\n",
    "                        [np.zeros((50, 50), dtype='float32') for _ in range(16)], axis=1)\n",
    "                bot = np.concatenate(\n",
    "                        [np.zeros((50, 50), dtype='float32') for _ in range(16)], axis=1)\n",
    "                end = np.concatenate(\n",
    "                        [np.zeros((50, 50), dtype='float32') for _ in range(16)], axis=1)\n",
    "                         \n",
    "                img = convert_img(np.concatenate([top, mid, bot, end], axis=0))\n",
    "                add_lables(img)\n",
    "                print(img.shape)\n",
    "                out.write(img)\n",
    "                \n",
    "            # Then show prediction, label, and diffrence\n",
    "            for i in range(labels[ts].shape[0]):\n",
    "                top = np.concatenate(\n",
    "                        [np.reshape(inputs[ts][19, j,:], (50,50)) for j in range(16)], axis=1)\n",
    "                mid = np.concatenate(\n",
    "                        [np.reshape(predictions[ts][i, j,:], (50,50)) for j in range(16)], axis=1)\n",
    "                bot = np.concatenate(\n",
    "                        [np.reshape(labels[ts][i, j,:], (50,50)) for j in range(16)], axis=1)\n",
    "                end = np.concatenate(\n",
    "                        [2**(np.reshape(predictions[ts][i, j,:], (50,50)) - np.reshape(labels[ts][i, j,:], (50,50))) for j in range(16)], axis=1)\n",
    "                \n",
    "                img = convert_img(np.concatenate([top, mid, bot, end], axis=0))\n",
    "                add_lables(img)\n",
    "                print(img.shape)\n",
    "                out.write(img)\n",
    "\n",
    "            # Now hold the last frame for 20 frames\n",
    "            for _ in range(20):\n",
    "                out.write(img)\n",
    "            \n",
    "            out.release()\n",
    "            \n",
    "    else:\n",
    "        print('skipped', directory)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<h1>Hello, world!</h1>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2\n",
    "\n",
    "Deep recurrent networks are tolerant to missing samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Test 1\n",
    "\n",
    "Train modls with increasing magnitudes of random missing (zeroed) samples and compare their performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing samples study (random missing pixels)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.predict_turbulence_recurrent import train\n",
    "from src.dataLoader.turbulence import Turbulence, RANDOM_SEED, LARGE_DATASET\n",
    "\n",
    "# Use a fixed seed  \n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for s in [0.9, 0.75, 0.5, 0.25, 0.1]:\n",
    "        \n",
    "    loader = Turbulence(pred_length=20, dataset_idx=LARGE_DATASET, debug=False)\n",
    "    \n",
    "    train(loader=loader, dataset_idx=LARGE_DATASET, num_batches=100000, pixel_dropout=s,\n",
    "          net_name='lstm_3_cells_20_pixel_dropout_{}'.format(s))\n",
    "    \n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "Comparing model perfomance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best lstm network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.predict_turbulence_recurrent import train\n",
    "from src.dataLoader.turbulence import Turbulence, LARGE_DATASET\n",
    "\n",
    "loader = Turbulence(pred_length=20, dataset_idx=LARGE_DATASET, input_noise=noise_data, debug=False)\n",
    "\n",
    "train(loader=loader, dataset_idx=LARGE_DATASET, num_batches=100000, net_name='lstm_3_cells_+20_{}'.format(scale))\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make videos of label, prediction, and difference\n",
    "import cv2\n",
    "\n",
    "# Video parameters\n",
    "fps = 8\n",
    "height, width = 50, 50\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "\n",
    "# Convert [0, 1] np.float32 to [0, 255] RGB cv2.uint8\n",
    "cmap = plt.get_cmap('jet')\n",
    "def convert_img(img):\n",
    "    mapped = cmap(img)\n",
    "    return cv2.normalize(mapped[:,:,:3], None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "\n",
    "# initialize video writer\n",
    "video_filename = 'output.avi'\n",
    "\n",
    "exp_root = './experiments/turbulence/pde'\n",
    "exp_folders = ['conv']\n",
    "npys = ['inputs.npz', 'predictions.npz', 'labels.npz']\n",
    "\n",
    "for i, directory in enumerate(exp_folders):\n",
    "    # Load input, prediction and label\n",
    "    if all([os.path.exists(os.path.join(exp_root, directory, f)) for f in npys]):\n",
    "        print('done')\n",
    "        ts = '10000'\n",
    "        input_dir, pred_dir, label_dir = [os.path.join(exp_root, directory, f) for f in npys]\n",
    "\n",
    "        with np.load(input_dir) as inputs, np.load(pred_dir) as predictions, np.load(label_dir) as labels:\n",
    "\n",
    "            out = cv2.VideoWriter(video_filename, fourcc, fps, (width, height*4))\n",
    "\n",
    "            # First show input sequence\n",
    "            for i in range(inputs[ts].shape[0]):\n",
    "                top = convert_img(np.reshape(inputs[ts][i, 0,:], (50,50)))\n",
    "                mid = np.zeros((50, 50, 3), dtype='uint8')\n",
    "                bot = np.zeros((50, 50, 3), dtype='uint8')\n",
    "                dif = np.zeros((50, 50, 3), dtype='uint8')\n",
    "                print(np.concatenate([top, mid, bot, dif], axis=0).shape)\n",
    "                out.write(np.concatenate([top, mid, bot, dif], axis=0))\n",
    "                \n",
    "            # Then show prediction and label\n",
    "            for i in range(labels[ts].shape[0]):\n",
    "                top = convert_img(np.reshape(inputs[ts][19, 0,:], (50,50)))\n",
    "                mid = convert_img(np.reshape(predictions[ts][i, 0,:], (50,50)))\n",
    "                bot = convert_img(np.reshape(labels[ts][i, 0,:], (50,50)))\n",
    "                dif = convert_img(10*2**(np.reshape(predictions[ts][i, 0,:], (50,50)) - np.reshape(labels[ts][i, 0,:], (50,50))))\n",
    "                print(np.concatenate([top, mid, bot, dif], axis=0).shape)\n",
    "                out.write(np.concatenate([top, mid, bot, dif], axis=0))\n",
    "                \n",
    "            # Then hold last image\n",
    "            for i in range(10):\n",
    "                out.write(np.concatenate([top, mid, bot, dif], axis=0))\n",
    "\n",
    "            # Now hold the last frame and show label and prediction beneth\n",
    "            out.release()\n",
    "            break\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Convolutional Baseline\n",
    "Below we use back-propigation to learn a linear model for predicting the next frame in the sequence. Back-propigation is  overkill for linear models, howerver the traing time is so fast it's not worth loading the problem into a least-squares minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False \n",
    "# completed = []\n",
    "completed = [(5,5), (5,20)]\n",
    "\n",
    "def lin_residual_cell(X):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    return tf.layers.conv2d(\n",
    "        X, 1, 5, name='lin_res_layer', padding='same', activation=None)\n",
    "    \n",
    "    return head\n",
    "\n",
    "def pde(X, skip_depth=3, num_features=1, kernel_size=5, encoder_kernel_size=1):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = tf.layers.conv2d(\n",
    "        X, filters=num_features, kernel_size=encoder_kernel_size, activation=None, name='map_input',\n",
    "        padding='valid')\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: lin_residual_cell(acc),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "\n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=1, kernel_size=1, activation=None, name='map_output'),\n",
    "        elems=head\n",
    "    )\n",
    "\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head\n",
    "\n",
    "for (history, pred_len) in itertools.product([5], [5, 20, 40, 60]):\n",
    "    if (history, pred_len) not in completed:\n",
    "        name = 'single_relu_pde'\n",
    "        num_batches = 15000 + pred_len * 1000\n",
    "        model = src.predict_pde_recurrent.train(\n",
    "            net_name=name, \n",
    "            pred_length=pred_len, \n",
    "            history_length=history, \n",
    "            network=pde,                                    \n",
    "            num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runge Kutta method\n",
    "\n",
    "First try - just add the definition for RK4 to the network. We see that we learn more slowly (this could be bacause of\n",
    "the increasing constraints on the learned model) and that for all prediction lengths greater than 5 there was basically no learning at all. We would like to try an experiment where we add prediction steps durring training but this could be complicated to implement in the current (non-eager) execution environment (tensorflow)\n",
    "\n",
    "Because it was an issue with training - we quadruple the alloted training time and ajusted relu activations to be leaky to prevent gradients from disapearing \n",
    "\n",
    "Second try - it seems that the added computation is not favorable here in terms of training. The performance is not significantly better then simply using fwd euler. We then tried adding additional layers and reduced features but this did not beat previous lstm models. Still could have applications for smoothness constraint, or learning Rk4 via components rather than directly performing gradient decent on the average of the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.predict_pde_recurrent import residual_cell\n",
    "\n",
    "completed = []\n",
    "# completed = [(5,5), (5,20)]\n",
    "\n",
    "def residual_cell(activation, skip_depth, num_features, kernel_width):\n",
    "    num_filters = num_features\n",
    "    kernel_size = (kernel_width, kernel_width)\n",
    "\n",
    "    # Pass activation to last layer and cell layers\n",
    "    head = activation\n",
    "\n",
    "    # Cell layers\n",
    "    for i in range(skip_depth):\n",
    "        head = tf.layers.conv2d(\n",
    "            head, num_filters, kernel_size, name='res_layer_{}'.format(i),\n",
    "            padding='same')\n",
    "        if i == skip_depth - 1:\n",
    "            head += activation\n",
    "        head = tf.nn.sigmoid(head)\n",
    "\n",
    "    # Skip layer\n",
    "    return head\n",
    "\n",
    "def runge_kutta_pde(X, pred_len, is_training, skip_depth=5, num_features=8, kernel_size=5, encoder_kernel_size=1):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    print(X.shape)\n",
    "    head = tf.layers.conv2d(\n",
    "        X, filters=num_features, kernel_size=encoder_kernel_size, activation=tf.nn.sigmoid, name='map_input',\n",
    "        padding='valid')\n",
    "    print(head.shape)\n",
    "    head = tf.layers.batch_normalization(head, training=is_training)\n",
    "    def rk4(y):\n",
    "        with tf.variable_scope('rk4', reuse=tf.AUTO_REUSE):\n",
    "            k1 = residual_cell(y, skip_depth, num_features, kernel_size)\n",
    "            k2 = residual_cell(y + 0.5 * k1, skip_depth, num_features, kernel_size)\n",
    "            k3 = residual_cell(y + 0.5 * k2, skip_depth, num_features, kernel_size)\n",
    "            k4 = residual_cell(y + k3, skip_depth, num_features, kernel_size)\n",
    "            return (k1 + 2*k2 + 2*k3 + k4) / 6\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: rk4(acc),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    print(head.shape)\n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=1, kernel_size=1, activation=tf.nn.sigmoid, name='map_output'),\n",
    "        elems=head\n",
    "    )\n",
    "    print(head.shape)\n",
    "\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (history, pred_len) in itertools.product([5], [5, 10, 20, 40]):\n",
    "    if (history, pred_len) not in completed:\n",
    "        name = 'runge_kutta_leaky_relu'\n",
    "        num_batches = 15000 + pred_len * 4000\n",
    "        model = src.predict_pde_recurrent.train(\n",
    "            net_name=name, \n",
    "            pred_length=pred_len, \n",
    "            history_length=history, \n",
    "            network=runge_kutta_pde,                                    \n",
    "            num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using increasing prediction length durring training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (2, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(2, ?, 50, 50, 8)\n",
      "(2, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8270d60b01534c4a91a22ed5565cc773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (3, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(3, ?, 50, 50, 8)\n",
      "(3, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86881f7ea224f5fbe693eea47e12073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (4, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(4, ?, 50, 50, 8)\n",
      "(4, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c58b3697744d118e555c1cc6662e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (5, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(5, ?, 50, 50, 8)\n",
      "(5, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3e4424b0a34b66a86c050cf3bebbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (6, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(6, ?, 50, 50, 8)\n",
      "(6, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedcf408474b4dd989b289b4a12f45da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (7, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(7, ?, 50, 50, 8)\n",
      "(7, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8be9cdb5ea46e787c747f08c9f5c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (8, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(8, ?, 50, 50, 8)\n",
      "(8, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b444963dbe41c0bf5c840b9e5741be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (9, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(9, ?, 50, 50, 8)\n",
      "(9, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20a188b3c564b4fbb0adce66a1ee43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (10, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(10, ?, 50, 50, 8)\n",
      "(10, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05a74568fe34b27aa47756a3d0be7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (11, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(11, ?, 50, 50, 8)\n",
      "(11, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533b3bd415e44259ac7028f395655a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (12, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(12, ?, 50, 50, 8)\n",
      "(12, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a049cca6896c4059923ba57e2cd2adbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (13, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(13, ?, 50, 50, 8)\n",
      "(13, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ac86b05f414903a8b27412a54e380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (14, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(14, ?, 50, 50, 8)\n",
      "(14, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bdf056b49d4b3c843a0717903fa9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (15, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(15, ?, 50, 50, 8)\n",
      "(15, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b68c485154a5e80edc1b2fcea95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (16, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(16, ?, 50, 50, 8)\n",
      "(16, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0dd1f2dc1943e4b3a237392b39aaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (17, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(17, ?, 50, 50, 8)\n",
      "(17, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3914ffb4fec74f59826fc840eb30bfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (18, ?, 50, 50)\n",
      "(?, 50, 50, 5)\n",
      "(?, 50, 50, 8)\n",
      "(18, ?, 50, 50, 8)\n",
      "(18, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0acc3c608e14602bf91db2f820aafe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a4769f6f47d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mstarting_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmulti_pred_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         retrain=True if pred_len > 0 else False)\n\u001b[0m",
      "\u001b[1;32m~\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net_name, save_dir, learning_rate, dataset_idx, loader, num_batches, pixel_dropout, conv_width, history_length, pred_length, encoder_kernel_size, network, retrain, multi_pred_len, starting_batch)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTurbulence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mpred_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\source\\orbitalMechanics\\src\\dataLoader\\turbulence.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size, patch_size, history_length, num_windows, pred_length, dataset_idx, input_noise, debug)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m# For small memory machines - just load the needed array rather than the whole .mat file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U_t'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mmdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatfile_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    250\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         '''\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try to exclude deprecation warnings\n",
    "target_pred_len = 20\n",
    "for pred_len in range(target_pred_len - 2):\n",
    "    num_batches = 6000 if pred_len != target_pred_len - 2 else 30000\n",
    "    model = src.predict_pde_recurrent.train(\n",
    "        net_name = 'runge_kutta_weighted_midpoint_p{}'.format(target_pred_len),\n",
    "        pred_length=pred_len + 2, \n",
    "        history_length=5, \n",
    "        network=runge_kutta_pde,\n",
    "        num_batches=num_batches,\n",
    "        starting_batch=num_batches*pred_len,\n",
    "        multi_pred_len=True,\n",
    "        retrain=True if pred_len > 0 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.predict_pde_recurrent import residual_cell\n",
    "\n",
    "completed = []\n",
    "# completed = [(5,5), (5,20)]\n",
    "\n",
    "def linear_cell(activation):\n",
    "    \n",
    "    return tf.layers.conv2d(activation, filters=1, kernel_size=1, activation=None)\n",
    "\n",
    "def linear_model(X, pred_len, is_training, skip_depth=5, num_features=8, kernel_size=5, encoder_kernel_size=1):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: linear_cell(acc),\n",
    "        elems=tf.zeros(pred_len), initializer=X, swap_memory=True)\n",
    "    print(head.shape)\n",
    "\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 1)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "(20, ?, 50, 50, 1)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea2972ca3aa4812b924d6ddd928b27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try to exclude deprecation warnings\n",
    "num_batches = 20000\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'linear_model',\n",
    "    pred_length=20, \n",
    "    history_length=1, \n",
    "    network=linear_model,                                    \n",
    "    num_batches=num_batches,\n",
    "    starting_batch=num_batches*pred_len,\n",
    "    multi_pred_len=True,\n",
    "    retrain=True if pred_len > 0 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing increased depth for encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.predict_pde_recurrent import residual_cell\n",
    "\n",
    "completed = []\n",
    "# completed = [(5,5), (5,20)]\n",
    "\n",
    "def residual_cell(activation, skip_depth, num_features, kernel_width):\n",
    "    num_filters = num_features\n",
    "    kernel_size = (kernel_width, kernel_width)\n",
    "\n",
    "    # Pass activation to last layer and cell layers\n",
    "    head = activation\n",
    "\n",
    "    # Cell layers\n",
    "    for i in range(skip_depth):\n",
    "        head = tf.layers.conv2d(\n",
    "            head, num_filters, kernel_size, name='res_layer_{}'.format(i),\n",
    "            padding='same')\n",
    "        if i == skip_depth - 1:\n",
    "            head += activation\n",
    "        head = tf.nn.sigmoid(head)\n",
    "\n",
    "    # Skip layer\n",
    "    return head\n",
    "\n",
    "def runge_kutta_extra_enc(X, pred_len, is_training, skip_depth=3, num_features=8, kernel_size=5, encoder_kernel_size=5):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = X\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=num_features, kernel_size=encoder_kernel_size, activation=tf.nn.sigmoid, name='map_input_1',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=num_features, kernel_size=encoder_kernel_size, activation=tf.nn.sigmoid, name='map_input_2',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=num_features, kernel_size=encoder_kernel_size, activation=tf.nn.sigmoid, name='map_input_3',\n",
    "        padding='same')\n",
    "    head = tf.layers.batch_normalization(head, training=is_training)\n",
    "    def rk4(y):\n",
    "        with tf.variable_scope('rk4', reuse=tf.AUTO_REUSE):\n",
    "            k1 = residual_cell(y, skip_depth, num_features, kernel_size)\n",
    "            k2 = residual_cell(y + 0.5 * k1, skip_depth, num_features, kernel_size)\n",
    "            k3 = residual_cell(y + 0.5 * k2, skip_depth, num_features, kernel_size)\n",
    "            k4 = residual_cell(y + k3, skip_depth, num_features, kernel_size)\n",
    "            return (k1 + k2 + k3 + k4) / 4\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: rk4(acc),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    \n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=4, kernel_size=1, activation=tf.nn.sigmoid, name='map_output_1'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=1, kernel_size=1, activation=tf.nn.relu, name='map_output_2'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (2, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dcd5ec81e9446a89b0d695adf3690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (3, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f03474a042747be8ce65844d214f9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (4, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ae33f2df784564822bd35a63e9ee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (5, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d46ed08cb624650aa072644dd33709d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (6, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70225adbf994ef3949f266a6f6f8884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (7, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e560ab8c4944e283bff46dd40faaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (8, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455a6c6ebda0474d9ae880fd658cf6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (9, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1445b198502b4491940089c6741e229f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (10, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b862937f2b4bfe9b57c686a455ffa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (11, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975d6f0dcfcd467b99e27750fe502a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (12, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb996f0f92453da6d36ffc776b740f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (13, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633cc5da1921465699b25ae78ed68172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (14, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61727559d5454c9580653c03f4d0dab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (15, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547f056bc4eb4c41a76af8c2413ea595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (16, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b8ad1bd7694e90a3b7ae3de7097508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (17, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e1be35666642618c460b271b78c06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (18, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075a27e0c8514d12a23777bd10bd36ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (19, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97d06a4baed46d48e38dfa63b6eea19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee08871decf403ebf4c54104ddbc6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (21, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf7dbb453894248beaa92099da9e403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (22, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46069bc1ac949308a2e213032615046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (23, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaecaa45ff04944ba66342e7ba68d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (24, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50d1e2562954189a785937adf40f0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (25, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a4775fcde74321b1042c6bb6c26242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (26, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7928fe23a4984adc921c022560bd019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (27, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d999d6895a14efb9c6a8f923ef2093d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (28, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8ecdddaccb4995957d468bb9e4b2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (29, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39043c7c568c413fa7ab7ee3fac8d2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (30, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f67103511294fd4b1de8a09abe149eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (31, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3360ea40144364a19806c22933221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (32, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db767c6a10a4475ada8499c47e62024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (33, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ff843ed93c49828a855dd422af5d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (34, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294961819af44ad8fb37b139261cae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (35, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f316d2d698ba45d9b210655c582e1cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (36, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ab92e927d8431d98067a8b1ab36f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (37, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cbcb100a3e4ad8bd4167116b460c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (38, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdd37d732cf472fb40df384e4fbb054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (39, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd76829440544f7eac5387327858a2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (40, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466d3220c6a44fe680e195910a9db1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (41, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39ccf2b49d840df8b8ab1e177cb3090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (42, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea167b3f45ca49309ce4f001e5355560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (43, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74714465a3e048aaab51a08563d9a73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (44, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d775905dd7d42bfba4adcefcb3561c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (45, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e12f4bfd1c7491fb6577e847dda0ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (46, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38e998e7810423ab9386fd139ca5b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (47, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af91a0bb33471eb3906e8629f6c60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (48, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f89ac52564642aeb623873f53ba2126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (49, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c40dbe515f465d8c1c57052f3d7f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (50, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e7e7bad5e443c280268ad9d4368062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (51, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ed247629f48b4a7310eee59575af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (52, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8515d20074d9438cb91866c2b5fe4fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (53, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ada5a05345405baa1eb8c839290a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (54, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b092e5384e400184ee438fd3c40a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (55, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6af08a7f7634576afb83826e597b73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (56, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d82bebaca2c448284693f0cf51647e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (57, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec48e9005c24992bada42dd1fccef8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (58, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3167298abd9f48a99c98609f5a6cc023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (59, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98465c89787e4c94a985b147719f2686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try to exclude deprecation warnings\n",
    "for pred_len in range(58):\n",
    "    num_batches = 6000\n",
    "    model = src.predict_pde_recurrent.train(\n",
    "        net_name = 'rk4_3_enc_2_dec_8_feat_3_skip',\n",
    "        pred_length=pred_len + 2, \n",
    "        history_length=5, \n",
    "        network=runge_kutta_extra_enc,                                    \n",
    "        num_batches=num_batches,\n",
    "        starting_batch=num_batches*pred_len,\n",
    "        multi_pred_len=True,\n",
    "        retrain=True if pred_len > 0 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a simple relu learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import src.predict_pde_recurrent\n",
    "\n",
    "\n",
    "def relu_learner(X, pred_len, is_training):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = X\n",
    "#     head = tf.layers.conv2d(\n",
    "#         head, filters=1, kernel_size=1, activation=tf.nn.relu, name='map_input',\n",
    "#         padding='same')\n",
    "        \n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: tf.layers.dense(units=1, inputs=acc, activation=tf.nn.relu),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    \n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0930 13:02:14.819687  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:256: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "W0930 13:02:14.835281  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:256: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0930 13:02:14.871274  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:270: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0930 13:02:14.871274  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:272: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0930 13:02:15.207543  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:285: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0930 13:02:15.223158  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:294: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0930 13:02:15.223158  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:330: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0930 13:02:16.705593  8132 deprecation_wrapper.py:119] From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py:348: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ad15488b16408cbb9ba8c9bf59512d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=40000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_batches = 40000\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'relu_dense_net',\n",
    "    pred_length=20, \n",
    "    history_length=5, \n",
    "    network=relu_learner,                                    \n",
    "    num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 1)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e55d1177ee045319a9f98a87511cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=40000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_batches = 40000\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'relu_single_dense_single_history',\n",
    "    pred_length=20, \n",
    "    history_length=1, \n",
    "    learning_rate=0.001,\n",
    "    network=relu_learner,                                    \n",
    "    num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import src.predict_pde_recurrent\n",
    "\n",
    "\n",
    "def linear_dense_learner(X, pred_len, is_training):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = X\n",
    "#     head = tf.layers.conv2d(\n",
    "#         head, filters=1, kernel_size=1, activation=tf.nn.relu, name='map_input',\n",
    "#         padding='same')\n",
    "        \n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: tf.layers.dense(units=1, inputs=acc, activation=None),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    \n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 1)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24ef69c082340648a0c26e0f3ff834c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=1000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_batches = 1000\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'simplest_model',\n",
    "    pred_length=20, \n",
    "    history_length=1, \n",
    "    learning_rate=0.001,\n",
    "    network=linear_dense_learner,                                    \n",
    "    num_batches=num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying multi-scale recurrent cells \n",
    "Use large convolutions to better approximate the PDE for the patch given that the linear model does so well there is likely global information that is missing. If this fails then we will lower the patch size and try again with the linaer model which should be closer to the expressive power of the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.predict_pde_recurrent import residual_cell\n",
    "\n",
    "completed = []\n",
    "# completed = [(5,5), (5,20)]\n",
    "\n",
    "def resnet_cell(activation, skip_depth, num_features, kernel_width):\n",
    "    # Pass activation to last layer and cell layers\n",
    "    head = activation\n",
    "    \n",
    "    num_filters = [8, 8, 64]\n",
    "    kernel_size = [1, 3, 1]\n",
    "    \n",
    "    # Cell layers\n",
    "    for i in range(skip_depth):\n",
    "        head = tf.layers.conv2d(\n",
    "            head, num_filters[i], kernel_size[i], name='res_layer_{}'.format(i),\n",
    "            padding='same')\n",
    "        if i == skip_depth - 1:\n",
    "            head += activation\n",
    "        head = tf.nn.relu(head)\n",
    "\n",
    "    # Skip layer\n",
    "    return head\n",
    "\n",
    "def res_net_encode_and_resid(X, pred_len, is_training, skip_depth=3, num_features=8, kernel_size=5, encoder_kernel_size=1):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = X\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=8, kernel_size=1, activation=tf.nn.relu, name='map_input_1',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=8, kernel_size=3, activation=tf.nn.relu, name='map_input_2',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=64, kernel_size=1, activation=tf.nn.relu, name='map_input_3',\n",
    "        padding='same')\n",
    "    \n",
    "    head = tf.layers.batch_normalization(head, training=is_training)\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: resnet_cell(acc, skip_depth, num_features, kernel_size),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    \n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=8, kernel_size=3, activation=tf.nn.relu, name='map_output_1',\n",
    "            padding='same'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=1, kernel_size=1, activation=tf.nn.relu, name='map_output_2'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (2, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6172746b2504c60b2a7a01b7314b928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (3, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06423053017d4e1f949858d5da672fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (4, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bafd693a3d489cbf6915f1f6eb00ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (5, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e517fb3c6624b868c90d2da38fe3599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (6, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3684a4dc95241409a0b30ddfa6eb63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (7, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d292dce7e2114c2490460545bff38574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (8, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30e51ec5cc742629b3c5c0fd03eb352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (9, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbc41dd66774b75947f9446c4b989a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (10, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d69ab0968d1471889ab3b239ea0b0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (11, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d79deabbcf54076b320e87734ee5c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (12, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098c036333804d3bbf2857e0888aa98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (13, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f285a6069b754dc2bfdbc356dc9f94b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (14, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b278c3a126447f6bf2f36030dc98e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (15, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785750560aa64b7aaf8f287ba31d3c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (16, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aeba6abbcd6427da7216ff006bc3e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (17, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bdc28fccc441e88b3f715b1459baa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (18, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2abe3383a944fdb93cd1f23bbb095b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (19, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2427b8869bcb4fc7a50e157c20cad8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b325e7585d46209b76ec70c5a191b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (21, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bdadf503d347b3aef13f057d08a40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (22, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8635c91a654032900f14bf83c2dcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6000), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to WriteFile: .\\experiments\\turbulence\\pde\\resnet_64_encoder_and_residual_cell_40_0.001-lr_5-hist\\network\\126000.meta.tmpc9d524911cb74ca49c34f0dcf18ebe87 : There is not enough space on the disk.\r\n; Unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a8101806a937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mstarting_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmulti_pred_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         retrain=True if pred_len > 0 else False)\n\u001b[0m",
      "\u001b[1;32m~\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net_name, save_dir, learning_rate, dataset_idx, loader, num_batches, pixel_dropout, conv_width, history_length, pred_length, encoder_kernel_size, network, retrain, multi_pred_len, starting_batch)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Completed Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# print('Saving the graph here:', J(LOG_DIR, 'network', str(num_batches + starting_batch)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'network'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstarting_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1198\u001b[0m               \u001b[0mmeta_graph_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m               \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m               save_debug_info=save_debug_info)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m         save_debug_info=save_debug_info)\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info, **kwargs)\u001b[0m\n\u001b[0;32m   1583\u001b[0m       \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m       \u001b[0msave_debug_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_debug_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1585\u001b[1;33m       **kwargs)\n\u001b[0m\u001b[0;32m   1586\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[1;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, strip_default_attrs, save_debug_info, **kwargs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m         as_text=as_text)\n\u001b[0m\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_debug_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[1;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[0;32m     72\u001b[0m                                             graph_def, float_format=''))\n\u001b[0;32m     73\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    536\u001b[0m   \"\"\"\n\u001b[0;32m    537\u001b[0m   \u001b[0mtemp_pathname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tmp\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mwrite_string_to_file\u001b[1;34m(filename, file_content)\u001b[0m\n\u001b[0;32m    345\u001b[0m   \"\"\"\n\u001b[0;32m    346\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, file_content)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prewrite_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     pywrap_tensorflow.AppendToFile(\n\u001b[1;32m--> 108\u001b[1;33m         compat.as_bytes(file_content), self._writable_file)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to WriteFile: .\\experiments\\turbulence\\pde\\resnet_64_encoder_and_residual_cell_40_0.001-lr_5-hist\\network\\126000.meta.tmpc9d524911cb74ca49c34f0dcf18ebe87 : There is not enough space on the disk.\r\n; Unknown error"
     ]
    }
   ],
   "source": [
    "# Try to exclude deprecation warnings\n",
    "for pred_len in range(38):\n",
    "    num_batches = 6000\n",
    "    model = src.predict_pde_recurrent.train(\n",
    "        net_name = 'resnet_64_encoder_and_residual_cell_40',\n",
    "        pred_length=pred_len + 2, \n",
    "        history_length=5, \n",
    "        network=res_net_encode_and_resid,                                    \n",
    "        num_batches=num_batches,\n",
    "        starting_batch=num_batches*pred_len,\n",
    "        multi_pred_len=True,\n",
    "        retrain=True if pred_len > 0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (5, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62fe4e3405945dabf5d5d2eec455683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=40000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5079db1ba65e4ec7bde7a5dcbf850cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=200000), HTML(value='')), layout=Layout(displ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just train 5 and 20 directly\n",
    "\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'resnet_64_encoder_and_residual_cell_5',\n",
    "    pred_length=5, \n",
    "    history_length=5, \n",
    "    network=res_net_encode_and_resid,                                    \n",
    "    num_batches=40000,\n",
    "    retrain=False)\n",
    "\n",
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'resnet_64_encoder_and_residual_cell_20_extra_long',\n",
    "    pred_length=20, \n",
    "    history_length=5, \n",
    "    network=res_net_encode_and_resid,                                    \n",
    "    num_batches=200000,\n",
    "    retrain=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0233afa4154c57b225d7b4822f5dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=2000000), HTML(value='')), layout=Layout(disp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net_name, save_dir, learning_rate, dataset_idx, loader, num_batches, pixel_dropout, conv_width, history_length, pred_length, encoder_kernel_size, network, retrain, multi_pred_len, starting_batch)\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mpre_train_steps\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcheckpoint_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'network'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstarting_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Completed Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1199\u001b[0m               \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m               save_debug_info=save_debug_info)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m         save_debug_info=save_debug_info)\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info, **kwargs)\u001b[0m\n\u001b[0;32m   1584\u001b[0m       \u001b[0msave_debug_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_debug_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1585\u001b[1;33m       **kwargs)\n\u001b[0m\u001b[0;32m   1586\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[1;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, strip_default_attrs, save_debug_info, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m         as_text=as_text)\n\u001b[0m\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_debug_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[1;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    537\u001b[0m   \u001b[0mtemp_pathname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tmp\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mwrite_string_to_file\u001b[1;34m(filename, file_content)\u001b[0m\n\u001b[0;32m    346\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, file_content)\u001b[0m\n\u001b[0;32m    107\u001b[0m     pywrap_tensorflow.AppendToFile(\n\u001b[1;32m--> 108\u001b[1;33m         compat.as_bytes(file_content), self._writable_file)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to WriteFile: .\\experiments\\turbulence\\pde\\resnet_64_encoder_and_residual_cell_20_extra_long_0.001-lr_5-hist_20-pred\\network\\950000.meta.tmp9f0421b537b148fca8ffba48e8e7b0f6 : There is not enough space on the disk.\r\n; Unknown error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aca1bb705cde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_net_encode_and_resid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnum_batches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     retrain=False)\n\u001b[0m",
      "\u001b[1;32m~\\source\\orbitalMechanics\\src\\predict_pde_recurrent.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net_name, save_dir, learning_rate, dataset_idx, loader, num_batches, pixel_dropout, conv_width, history_length, pred_length, encoder_kernel_size, network, retrain, multi_pred_len, starting_batch)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mlabel_sequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predictions_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstarting_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredicted_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstarting_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlabel_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inputs_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstarting_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavez_compressed\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \"\"\"\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[0m_savez\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m                 format.write_array(fid, val,\n\u001b[0;32m    727\u001b[0m                                    \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m                                    pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    729\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;31m# Stage arrays in a temporary file on disk, before writing to zip.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m                     \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'external_loop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'buffered'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zerosize_ok'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                     buffersize=buffersize, order='C'):\n\u001b[1;32m--> 645\u001b[1;33m                 \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1013\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1016\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "model = src.predict_pde_recurrent.train(\n",
    "    net_name = 'resnet_64_encoder_and_residual_cell_20_extra_long',\n",
    "    pred_length=20, \n",
    "    history_length=5, \n",
    "    network=res_net_encode_and_resid,                                    \n",
    "    num_batches=2000000,\n",
    "    retrain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Fwd Euler with same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import src.predict_pde_recurrent\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.predict_pde_recurrent import residual_cell\n",
    "\n",
    "completed = []\n",
    "# completed = [(5,5), (5,20)]\n",
    "\n",
    "def brandon_cell(activation, skip_depth):  \n",
    "    # Conv layers\n",
    "    num_filters = [8, 8, 32]\n",
    "    kernel_size = [1, 3, 1]\n",
    "    \n",
    "    head1 = activation\n",
    "    for i in range(skip_depth):\n",
    "        if i != 0:\n",
    "            head1 = tf.nn.relu(head1)\n",
    "        head1 = tf.layers.conv2d(\n",
    "            head1, num_filters[i], kernel_size[i], name='small_scale_layer_{}'.format(i), padding='same')  \n",
    "        \n",
    "    # FC component\n",
    "    head2 = activation\n",
    "    head2 = tf.layers.conv2d(\n",
    "        head2, filters=16, kernel_size=9, strides=5, name='big_scale_layer_1', activation=tf.nn.relu, padding='valid')  \n",
    "    head2 = tf.layers.conv2d(\n",
    "        head2, filters=32, kernel_size=5, strides=1, name='big_scale_layer_2', activation=tf.nn.relu, padding='same')  \n",
    "    head2 = tf.layers.conv2d_transpose(\n",
    "        head2, filters=32, kernel_size=10, strides=5, name='big_scale_layer_3', activation=tf.nn.relu, padding='valid')  \n",
    "    \n",
    "    head = tf.concat([head1, head2], -1)\n",
    "        \n",
    "    head = tf.nn.relu(head + activation)\n",
    "\n",
    "    # Skip layer\n",
    "    return head\n",
    "\n",
    "def multi_scale_concat_downsample(X, pred_len, is_training, skip_depth=3, encoder_kernel_size=1):\n",
    "    # Input 50 x 50 X history_len patch\n",
    "    # Map this patch to match the residual cell size\n",
    "    head = X\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=8, kernel_size=3, activation=tf.nn.relu, name='map_input_1',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=8, kernel_size=3, activation=tf.nn.relu, name='map_input_2',\n",
    "        padding='same')\n",
    "    head = tf.layers.conv2d(\n",
    "        head, filters=64, kernel_size=5, strides=2, activation=tf.nn.relu, name='map_input_3',\n",
    "        padding='same')\n",
    "    \n",
    "    head = tf.layers.batch_normalization(head, training=is_training)\n",
    "\n",
    "    head = tf.scan(\n",
    "        fn=lambda acc, _: brandon_cell(acc, skip_depth),\n",
    "        elems=tf.zeros(pred_len), initializer=head, swap_memory=True)\n",
    "    \n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d_transpose(inputs=elem, filters=8, kernel_size=5, strides=2, activation=tf.nn.relu, name='map_output_1',\n",
    "            padding='same'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.map_fn(\n",
    "        fn=lambda elem:\n",
    "            tf.layers.conv2d(inputs=elem, filters=1, kernel_size=3, name='map_output_2', padding='same'),\n",
    "        elems=head\n",
    "    )\n",
    "    head = tf.squeeze(head)\n",
    "\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (2, ?, 50, 50)\n",
      "Network shape: <unknown>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dcd3adf5c54e959e9217e19e78ef63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (4, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715b968109214b6aae9ef64831196d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (6, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c999baf137164feebde0d054a9d9d399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (8, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1181b68d64784b5fb012e27925fa5619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (10, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea337e306384cbd9c2b89462a6a82ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (12, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee343df985548b590fe195f3a17ec25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (14, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becbd391d050432cbb2dbbbdeb75e24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (16, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2314e980f848a3b246dfbf7a31389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (18, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d79b1edc31941a182c040cd16dd87cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 50, 50, 5)\n",
      "Output shape: (20, ?, 50, 50)\n",
      "Network shape: <unknown>\n",
      "restoring weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ccd17f5905480388de6764e12d2964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=30000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches_so_far = 0\n",
    "target_pred_len = 20\n",
    "starting_len = 2\n",
    "for pred_len in range(starting_len, target_pred_len + 1, 2):\n",
    "    num_batches = 10000 if pred_len != target_pred_len else 30000\n",
    "    model = src.predict_pde_recurrent.train(\n",
    "        net_name = 'multi_scale_concat_downsample_p{}_by_2'.format(target_pred_len),\n",
    "        pred_length=pred_len, \n",
    "        history_length=5, \n",
    "        network=multi_scale_concat_downsample,                                    \n",
    "        num_batches=num_batches,\n",
    "        starting_batch=batches_so_far,\n",
    "        multi_pred_len=True,\n",
    "        retrain=True if pred_len > starting_len else False)\n",
    "    batches_so_far += num_batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
