{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Report: 06/07/2019 -- 06/17/2019\n",
    "\n",
    "## Brief: What was done previously\n",
    "Previous work discovered multiple mechanisms to improve the accuracy of prediction. This week we quantify the performance of those methods and test them against a standard baseline.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "1. Hypothesis 1: Prediction accuracy vs increased magnitude of sensor noise (fixed gaussians per pixel noise)\n",
    "2. Hypothesis 2: Prediction accuracy vs increasing number of missing sensor samples (entire patch - randomized drop-out)\n",
    "3. Hypothesis 3: Prediction accuracy vs increasing number of sensor values (per pixel randomized drop-out)\n",
    "\n",
    "\n",
    "\n",
    "## Summary of Main Results and Discussions\n",
    "\n",
    "\n",
    "\n",
    "### Experiment 1 results and discussion\n",
    "Put main result and conclusions here. Discuss importance/impact in terms of the project goals.\n",
    "\n",
    "### Experiment 2: results and discussion\n",
    "Put main result and conclusions here. Discuss importance/impact in terms of the project goals.\n",
    "\n",
    "\n",
    "## Plan for next effort\n",
    "What will be tested/extended from this week?\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "Deep recurrent networks are tolerant to sensor noise below a certain magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation accuracy over increasing fixed sample level sensor noise\n",
    "We add decreasing magnitudes of gaussian noise to the input and predict the clean future signal. We expect, for\n",
    "high levels of noise, the model to over-fit to the noise. However after some threshold we expect the model to learn \n",
    "to recover from small perturbations by learning the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "C:\\Users\\brandon\\source\\orbitalMechanics\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
      "Input shape: (20, ?, 2500)\nOutput shape: (20, ?, 50, 50)\nEncoder input shape: [20, None, 2500]\nWARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:23: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "Padded input shape: [20, 64, 2500]\n",
      "[20, 64, 250]\nWARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:265: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
      "INFO:tensorflow:Summary name Loss Histogram is illegal; using Loss_Histogram instead.\n",
      "INFO:tensorflow:Summary name Mean Abs Error is illegal; using Mean_Abs_Error instead.\n",
      "( 0.28434148 0 )\n",
      "( 0.008584116 500 )\n",
      "0.0042633675 1000\n",
      "0.0039089536 1500\n",
      "0.0024253237 2000\n",
      "0.0019332524 2500\n",
      "0.0016941525 3000\n",
      "0.0014729245 3500\n",
      "0.0014514588 4000\n",
      "0.0012245055 4500\n",
      "0.0010255383 5000\n",
      "0.0012449799 5500\n",
      "0.00089282106 6000\n",
      "0.00084457576 6500\n",
      "0.0008128905 7000\n",
      "0.0007957142 7500\n",
      "0.00070202566 8000\n",
      "0.00062720926 8500\n",
      "0.0006918573 9000\n",
      "0.0006323288 9500\n",
      "0.00068089267 10000\n",
      "0.0006083477 10500\n",
      "0.00049844885 11000\n",
      "0.0005395411 11500\n",
      "0.0005319488 12000\n",
      "0.0005311653 12500\n",
      "0.0004562245 13000\n",
      "0.0004598029 13500\n",
      "0.00047891663 14000\n",
      "0.00043791338 14500\n",
      "0.00043318895 15000\n",
      "0.00043191324 15500\n",
      "0.0004694502 16000\n",
      "0.00043992372 16500\n",
      "0.000436419 17000\n",
      "0.00040350333 17500\n",
      "0.0003970627 18000\n",
      "0.00043905684 18500\n",
      "0.00037809167 19000\n",
      "0.00036242962 19500\n",
      "0.00033960625 20000\n",
      "0.00034144 20500\n",
      "0.00036560636 21000\n",
      "0.0003310248 21500\n",
      "0.00032965222 22000\n",
      "0.00031031016 22500\n",
      "0.00033610073 23000\n",
      "0.00030078963 23500\n",
      "0.00029091683 24000\n",
      "0.0003078152 24500\n",
      "0.00028794847 25000\n",
      "0.0002984425 25500\n",
      "0.0002966515 26000\n",
      "0.00029806604 26500\n",
      "0.0002847724 27000\n",
      "0.00027923734 27500\n",
      "0.00029691966 28000\n",
      "0.0002874807 28500\n",
      "0.0002758066 29000\n",
      "0.00023807198 29500\n",
      "0.00026824235 30000\n",
      "0.0002841955 30500\n",
      "0.00024166265 31000\n",
      "0.00026976108 31500\n",
      "0.00026813665 32000\n",
      "0.00026504084 32500\n",
      "0.0002488675 33000\n",
      "0.00027444586 33500\n",
      "0.00024991806 34000\n",
      "0.00025704916 34500\n",
      "0.00025202788 35000\n",
      "0.00022868393 35500\n",
      "0.00022888719 36000\n",
      "0.0002299604 36500\n",
      "0.00022922395 37000\n",
      "0.00021289647 37500\n",
      "0.00026046197 38000\n",
      "0.00023256843 38500\n",
      "0.00023495108 39000\n",
      "0.00021317028 39500\n",
      "0.00021629059 40000\n",
      "0.00024726026 40500\n",
      "0.00021556644 41000\n",
      "0.00021508758 41500\n",
      "0.00017108038 42000\n",
      "0.00022413931 42500\n",
      "0.00023195187 43000\n",
      "0.00020586704 43500\n",
      "0.00021249028 44000\n",
      "0.00019313135 44500\n",
      "0.00021857613 45000\n",
      "0.00019837276 45500\n",
      "0.00019012294 46000\n",
      "0.00020575183 46500\n",
      "0.00021268548 47000\n",
      "0.00018745563 47500\n",
      "0.00020018926 48000\n",
      "0.00020500753 48500\n",
      "0.00019411309 49000\n",
      "0.00019874432 49500\n",
      "0.0001815286 50000\n",
      "0.00020585457 50500\n",
      "0.00018123051 51000\n",
      "0.00019176463 51500\n",
      "0.00017465072 52000\n",
      "0.00017539496 52500\n",
      "0.00018768206 53000\n",
      "0.00017393524 53500\n",
      "0.00016268957 54000\n",
      "0.00018827265 54500\n",
      "0.00018290311 55000\n",
      "0.00019271791 55500\n",
      "0.00017499688 56000\n",
      "0.00020404728 56500\n",
      "0.00018205939 57000\n",
      "0.00017623937 57500\n",
      "0.00016531162 58000\n",
      "0.00015752026 58500\n",
      "0.00017356306 59000\n",
      "0.00015974263 59500\n",
      "0.00015474184 60000\n",
      "0.00017111325 60500\n",
      "0.00016039342 61000\n",
      "0.00017297515 61500\n",
      "0.0001602365 62000\n",
      "0.00013925825 62500\n",
      "0.00015253873 63000\n",
      "0.00016761124 63500\n",
      "0.00016583593 64000\n",
      "0.00015424674 64500\n",
      "0.00016318118 65000\n",
      "0.00015848587 65500\n",
      "0.00016145987 66000\n",
      "0.0001596421 66500\n",
      "0.00013845522 67000\n",
      "0.00016098373 67500\n",
      "0.00026856206 68000\n",
      "0.0001607379 68500\n",
      "0.00014792998 69000\n",
      "0.00014055177 69500\n",
      "0.0001391551 70000\n",
      "0.0001457515 70500\n",
      "0.00013746745 71000\n",
      "0.00016264932 71500\n",
      "0.00015491867 72000\n",
      "0.00014042314 72500\n",
      "0.00012376631 73000\n",
      "0.00013957724 73500\n",
      "0.00014901956 74000\n",
      "0.00014651485 74500\n",
      "0.0001389388 75000\n",
      "0.0001380593 75500\n",
      "0.00012561976 76000\n",
      "0.00013243288 76500\n",
      "0.00013168472 77000\n",
      "0.00013373699 77500\n",
      "0.00013928779 78000\n",
      "0.00012261486 78500\n",
      "0.0001219059 79000\n",
      "0.0001323695 79500\n",
      "0.00012761846 80000\n",
      "0.00012447571 80500\n",
      "0.00013476872 81000\n",
      "0.00012254734 81500\n",
      "0.00011687512 82000\n",
      "0.000121801066 82500\n",
      "0.00012435808 83000\n",
      "0.00012687084 83500\n",
      "0.00013274743 84000\n",
      "0.00013091536 84500\n",
      "0.00021732529 85000\n",
      "0.00013585322 85500\n",
      "0.00011834815 86000\n",
      "0.00013579018 86500\n",
      "0.00012486336 87000\n",
      "0.00011480501 87500\n",
      "0.00012425482 88000\n",
      "0.00013007832 88500\n",
      "0.0001408965 89000\n",
      "0.00012106012 89500\n",
      "0.00012814591 90000\n",
      "0.0001113602 90500\n",
      "0.0001259614 91000\n",
      "0.00012670233 91500\n",
      "0.000114310846 92000\n",
      "0.000116156916 92500\n",
      "0.000113398106 93000\n",
      "0.000119338045 93500\n",
      "0.00011176827 94000\n",
      "0.000112207454 94500\n",
      "0.00011666276 95000\n",
      "0.00011310226 95500\n",
      "0.00011961507 96000\n",
      "0.00012305677 96500\n",
      "0.00013321268 97000\n",
      "0.00011269494 97500\n",
      "0.000110164794 98000\n",
      "0.000112914386 98500\n",
      "0.00011765437 99000\n",
      "0.0001055639 99500\n",
      "0.00010631586 100000\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to delete files with this prefix.\n",
      "Input shape: (20, ?, 2500)\nOutput shape: (20, ?, 50, 50)\nEncoder input shape: [20, None, 2500]\nPadded input shape: [20, 64, 2500]\n",
      "[20, 64, 250]\n",
      "INFO:tensorflow:Summary name Loss Histogram is illegal; using Loss_Histogram instead.\n",
      "INFO:tensorflow:Summary name Mean Abs Error is illegal; using Mean_Abs_Error instead.\n",
      "( 0.28342792 0 )\n",
      "( 0.007678068 500 )\n",
      "0.003534946 1000\n",
      "0.0029943835 1500\n",
      "0.001601984 2000\n",
      "0.0013288099 2500\n",
      "0.0013057196 3000\n",
      "0.0010637005 3500\n",
      "0.0010536645 4000\n",
      "0.0009452954 4500\n",
      "0.0008658965 5000\n",
      "0.00088180567 5500\n",
      "0.00075537304 6000\n",
      "0.00067305815 6500\n",
      "0.00065538596 7000\n",
      "0.00069409225 7500\n",
      "0.00064149685 8000\n",
      "0.0005556494 8500\n",
      "0.0005770979 9000\n",
      "0.00049512106 9500\n",
      "0.0005324953 10000\n",
      "0.0005010978 10500\n",
      "0.0004925978 11000\n",
      "0.0004679514 11500\n",
      "0.0005070594 12000\n",
      "0.00045348884 12500\n",
      "0.00040374082 13000\n",
      "0.00040303767 13500\n",
      "0.00039559123 14000\n",
      "0.00037534029 14500\n",
      "0.0003799193 15000\n",
      "0.00034220453 15500\n",
      "0.00034523406 16000\n",
      "0.00033678033 16500\n",
      "0.00031164565 17000\n",
      "0.00031434745 17500\n",
      "0.0003253619 18000\n",
      "0.0003159585 18500\n",
      "0.0003130001 19000\n",
      "0.00032141613 19500\n",
      "0.000289307 20000\n",
      "0.00025759963 20500\n",
      "0.00026229117 21000\n",
      "0.00025579572 21500\n",
      "0.000252218 22000\n",
      "0.00025473544 22500\n",
      "0.00025771666 23000\n",
      "0.0002371356 23500\n",
      "0.00022439961 24000\n",
      "0.00022651046 24500\n",
      "0.00025599444 25000\n",
      "0.000233866 25500\n",
      "0.00023481852 26000\n",
      "0.00021209137 26500\n",
      "0.00020927454 27000\n",
      "0.0002265641 27500\n",
      "0.00020658551 28000\n",
      "0.00019102081 28500\n",
      "0.00018693789 29000\n",
      "0.00019004344 29500\n",
      "0.00017505194 30000\n",
      "0.00018851472 30500\n",
      "0.0001822819 31000\n",
      "0.00019035404 31500\n",
      "0.00018448934 32000\n",
      "0.00018796523 32500\n",
      "0.0001765327 33000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Gaussian noise study\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.predict_turbulence_recurrent import train\n",
    "from src.dataLoader.turbulence import Turbulence, RANDOM_SEED, LARGE_DATASET\n",
    "\n",
    "# Use a fixed seed for noise    \n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for scale in [2, 1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.0001, 0]:\n",
    "    noise_data = np.random.normal(size=(360, 279, 1000), scale=scale)\n",
    "    \n",
    "    loader = Turbulence(pred_length=20, dataset_idx=LARGE_DATASET, input_noise=noise_data, debug=False)\n",
    "    \n",
    "    train(loader=loader, dataset_idx=LARGE_DATASET, num_batches=100000, net_name='lstm_3_cells_20_static_noise_{}'.format(scale))\n",
    "    \n",
    "    tf.reset_default_graph()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results\n",
    "\n",
    "In this test given a 3 layer encoder/decoder with 250 units per layer, we see that the performance of the model is \n",
    "resistant to up to 5% noise without any degradation in predictive power. Even with 100% noise the model learned to \n",
    "reject some amount of noise and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n\nConsider using IPython.display.IFrame instead\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<chart_studio.tools.PlotlyDisplay object>",
      "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/50.embed\" height=\"525px\" width=\"100%\"></iframe>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "# Compare accuracy of model with increasing fixed noise\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "    \n",
    "# Compare MSE vs magnitude of noise\n",
    "noise = [1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01]\n",
    "validation_accuracy = [8.1668e-4, 5.475e-4, 2.8722e-4, 1.0855e-4, 4.5386e-5, 3.1529e-5, 2.7214e-5, 2.0735e-5]\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = noise,\n",
    "    y = validation_accuracy,\n",
    "    name=\"\"\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title=\"Magnitude of Sensor Noise vs Prediction Accuracy\",\n",
    "    xaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        title='Standard Deviation of Added Gaussian Noise',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        title='Mean Squared Validation Error over 20 Steps',\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='static_noise_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4887bf6674dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#             print(foo.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label_100000_0.0008166771149262786.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_100000_0.0008166771149262786.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ],
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error"
    }
   ],
   "source": [
    "# Visualize learned data\n",
    "import numpy as np\n",
    "\n",
    "exp_dir = './experiments/turbulence/recurrent_scaled_mse'\n",
    "for directory in os.listdir(exp_dir):\n",
    "    # for file in os.listdir(os.path.join(exp_dir, directory)):\n",
    "    #     if file.endswith('.npy') and file.startswith('label_'):\n",
    "    #         print(os.path.join(exp_dir, directory, file))\n",
    "    #         with np.load(os.path.join(exp_dir, directory, file)) as foo:\n",
    "    #             print(foo.shape)\n",
    "    try:\n",
    "        with np.load(os.path.join(exp_dir, directory, 'label_100000_0.0008166771149262786.npy')) as labels:\n",
    "            with np.load(os.path.join(exp_dir, directory, 'pred_100000_0.0008166771149262786.npy')) as predictions:\n",
    "                foo = {key:labels[key].item() for key in labels}\n",
    "                for arr in predictions.keys():\n",
    "                    print(predictions[arr].item())\n",
    "                    for key, value in dict(predictions[arr].tolist()).items():\n",
    "                        print (key,':', value.shape)\n",
    "                    # print(dict(labels))\n",
    "                    # print(dict(labels[key].tolist())['2000'])\n",
    "                    # print(predictions[key])\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "#     \n",
    "# \n",
    "# trace = go.Heatmap(\n",
    "#     z=frame,\n",
    "#     colorscale='Viridis')\n",
    "# data=[trace]\n",
    "# py.iplot(data, filename='basic-heatmap')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2\n",
    "\n",
    "Sample level dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Test 1\n",
    "\n",
    "Description of test 1 of hypothesis 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1, hyp 2 code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}