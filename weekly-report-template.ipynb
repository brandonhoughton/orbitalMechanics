{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Report: 06/07/2019 -- 06/17/2019\n",
    "\n",
    "## Brief: What was done previously\n",
    "Previous work discovered multiple mechanisms to improve the accuracy of prediction. This week we quantify the performance of those methods and test them against a standard baseline.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "1. Hypothesis 1: Prediction accuracy vs increased magnitude of sensor noise (fixed gausian per pixel noise)\n",
    "2. Hypothesis 2: Prediction accuracy vs increasing number of missing sensor samples (entire patch - randomized drop-out)\n",
    "3. Hypothesis 3: Prediction accuracy vs increasing number of sensor values (per pixel randomized drop-out)\n",
    "\n",
    "\n",
    "\n",
    "## Summary of Main Results and Discussions\n",
    "\n",
    "\n",
    "\n",
    "### Experiment 1 results and discussion\n",
    "Put main result and conclusions here. Discuss importance/impact in terms of the project goals.\n",
    "\n",
    "### Experiment 2: results and discussion\n",
    "Put main result and conclusions here. Discuss importance/impact in terms of the project goals.\n",
    "\n",
    "\n",
    "## Plan for next effort\n",
    "What will be tested/extended from this week?\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "Deep recurrent networks are tolerant to sensor noise below a certain magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation accuracy over increasing fixed sample level sensor noise\n",
    "We add decreasing magnitudes of gaussian noise to the input and predict the clean future signal. We expect, for\n",
    "high levels of noise, the model to over-fit to the noise. However after some threshold we expect the model to learn \n",
    "to recover from small perturbations by learning the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "C:\\Users\\brandon\\source\\orbitalMechanics\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
      "Input shape: (20, ?, 2500)\nOutput shape: (20, ?, 50, 50)\nEncoder input shape: [20, None, 2500]\nWARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:23: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "Padded input shape: [20, 64, 2500]\n[20, 64, 250]\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\source\\orbitalMechanics\\src\\predict_turbulence_recurrent.py:265: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\brandon\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
      "INFO:tensorflow:Summary name Loss Histogram is illegal; using Loss_Histogram instead.\n",
      "INFO:tensorflow:Summary name Mean Abs Error is illegal; using Mean_Abs_Error instead.\n",
      "( 0.28463957 0 )\n",
      "0.037029643 20\n",
      "0.035043627 40\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Test 1 code\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.predict_turbulence_recurrent import train\n",
    "from src.dataLoader.turbulence import Turbulence, RANDOM_SEED, LARGE_DATASET\n",
    "\n",
    "# Use a fixed seed for noise\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for scale in [2, 1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.0001, 0]:\n",
    "    noise_data = np.random.normal(size=(360, 279, 1000), scale=scale)\n",
    "    \n",
    "    loader = Turbulence(pred_length=20, dataset_idx=LARGE_DATASET, input_noise=noise_data, debug=False)\n",
    "    \n",
    "    train(loader=loader, dataset_idx=LARGE_DATASET, num_batches=100000, net_name='lstm_3_cells_20_static_noise_{}'.format(scale))\n",
    "    \n",
    "    tf.reset_default_graph()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results\n",
    "\n",
    "In this test given a 3 layer encoder/decoder with 250 units per layer, we see that the performance of the model is \n",
    "resistant to up to 5% noise without any degradation in predictive power. Even with 100% noise the model learned to \n",
    "reject some amount of noise and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n\nConsider using IPython.display.IFrame instead\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<chart_studio.tools.PlotlyDisplay object>",
      "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bhoughton/50.embed\" height=\"525px\" width=\"100%\"></iframe>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "# Compare accuracy of model with increasing fixed noise\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "    \n",
    "# Compare MSE vs magnitude of noise\n",
    "noise = [1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01]\n",
    "validation_accuracy = [8.1668e-4, 5.475e-4, 2.8722e-4, 1.0855e-4, 4.5386e-5, 3.1529e-5, 2.7214e-5, 2.0735e-5]\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = noise,\n",
    "    y = validation_accuracy,\n",
    "    name=\"\"\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title=\"Magnitude of Sensor Noise vs Prediction Accuracy\",\n",
    "    xaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        title='Standard Deviation of Added Gaussian Noise',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "        title='Mean Squared Validation Error over 20 Steps',\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='static_noise_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4887bf6674dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#             print(foo.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label_100000_0.0008166771149262786.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_100000_0.0008166771149262786.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ],
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error"
    }
   ],
   "source": [
    "# Visualize learned data\n",
    "import numpy as np\n",
    "\n",
    "exp_dir = './experiments/turbulence/recurrent_scaled_mse'\n",
    "for directory in os.listdir(exp_dir):\n",
    "    # for file in os.listdir(os.path.join(exp_dir, directory)):\n",
    "    #     if file.endswith('.npy') and file.startswith('label_'):\n",
    "    #         print(os.path.join(exp_dir, directory, file))\n",
    "    #         with np.load(os.path.join(exp_dir, directory, file)) as foo:\n",
    "    #             print(foo.shape)\n",
    "    try:\n",
    "        with np.load(os.path.join(exp_dir, directory, 'label_100000_0.0008166771149262786.npy')) as labels:\n",
    "            with np.load(os.path.join(exp_dir, directory, 'pred_100000_0.0008166771149262786.npy')) as predictions:\n",
    "                foo = {key:labels[key].item() for key in labels}\n",
    "                for arr in predictions.keys():\n",
    "                    print(predictions[arr].item())\n",
    "                    for key, value in dict(predictions[arr].tolist()).items():\n",
    "                        print (key,':', value.shape)\n",
    "                    # print(dict(labels))\n",
    "                    # print(dict(labels[key].tolist())['2000'])\n",
    "                    # print(predictions[key])\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "#     \n",
    "# \n",
    "# trace = go.Heatmap(\n",
    "#     z=frame,\n",
    "#     colorscale='Viridis')\n",
    "# data=[trace]\n",
    "# py.iplot(data, filename='basic-heatmap')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2\n",
    "\n",
    "Sample level dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Test 1\n",
    "\n",
    "Description of test 1 of hypothesis 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1, hyp 2 code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}